<!DOCTYPE html>
<html>

<head>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <!-- This adapter.js file de-prefixes the webkit* and moz* prefixed RTC
             methods. When RTC becomes a more solid standard, this adapter should no
             longer be necessary. -->
    <!-- <script src="https://webrtc.googlecode.com/svn/trunk/samples/js/base/adapter.js"></script> -->
    <style>
        html,
        body {
            background-color: #333;
        }

        video {
            width: 320px;
            height: 240px;
            border: 1px solid black;
        }

        .btn-group {
            /* position: absolute;
            bottom: 20%; */
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .btn-group .button {
            background-color: #e7e7e7;
            /* Green */
            border: 1px solid #b6b3b3;
            color: black;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            cursor: pointer;
            float: left;
            transition-duration: 0.4s;
        }

        .btn-group .button:not(:last-child) {
            border-right: none;
            /* Prevent double borders */
        }

        .btn-group .button:hover {
            background-color: #b6b3b3;
        }
    </style>

    <script src="https://cdn.socket.io/socket.io-1.4.5.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>
    <!-- <script src="https://www.webrtc-experiment.com/Canvas-Designer/canvas-designer-widget.js"></script> -->
    <script src="scripts/canvas-designer-widget.js"></script>
   
    <script>
        /** CONFIG **/
        var SIGNALING_SERVER = "http://webrtc-webrtc.193b.starter-ca-central-1.openshiftapps.com/";
        var USE_AUDIO = true;
        var USE_VIDEO = true;
        var DEFAULT_CHANNEL = 'some-global-channel-name';
        var MUTE_AUDIO_BY_DEFAULT = false;

        /** You should probably use a different stun server doing commercial stuff **/
        /** Also see: https://gist.github.com/zziuni/3741933 **/
        var ICE_SERVERS = [{
            url: "stun:stun.l.google.com:19302"
        }];
    </script>

    <script>
        var signaling_socket = null; /* our socket.io connection to our webserver */
        var local_media_stream = null; /* our own microphone / webcam */
        var peers = {}; /* keep track of our peer connections, indexed by peer_id (aka socket.io id) */
        var peer_media_elements = {}; /* keep track of our <video>/<audio> tags, indexed by peer_id */
        var peer_connection;
        var data_channel;
        var receive_channel;
        var local_media;
        var isInitiator;

        function init() {
            console.log("Connecting to signaling server");
            signaling_socket = io(SIGNALING_SERVER);
            signaling_socket = io();

            signaling_socket.on('connect', function () {
                console.log("Connected to signaling server");
                setup_local_media(function () {
                    /* once the user has given us access to their
                     * microphone/camcorder, join the channel and start peering up */
                    join_chat_channel(DEFAULT_CHANNEL, {
                        'whatever-you-want-here': 'stuff'
                    });
                });
            });

            signaling_socket.on('disconnect', function () {
                console.log("Disconnected from signaling server");
                /* Tear down all of our peer connections and remove all the
                 * media divs when we disconnect */
                for (peer_id in peer_media_elements) {
                    peer_media_elements[peer_id].remove();
                }
                for (peer_id in peers) {
                    peers[peer_id].close();
                }

                peers = {};
                peer_media_elements = {};
            });

            function join_chat_channel(channel, userdata) {
                signaling_socket.emit('join', {
                    "channel": channel,
                    "userdata": userdata
                });
            }

            function part_chat_channel(channel) {
                signaling_socket.emit('part', channel);
            }

            async function createConnection(data_channel) {
                // create data channel for whiteboard
                onDataChannelCreated(data_channel);
                console.log('Created send data channel');
                var ready_state = data_channel.readyState;
                console.log('Send channel state is: ' + ready_state);
            }

            function onDataChannelCreated(channel) {
                var ready_state = channel.readyState;
                channel.onopen = function (event) {
                    if (ready_state === 'open') {
                        console.log('CHANNEL opened!')
                        channel.send('Hi you!');

                    } else {
                        // console.log('Connection was lost. Peer closed the connection.')
                    }
                    // if (designer.pointsLength > 0) {
                    //     console.log('Designer Sync')
                    //     // you seems having data to be synced with new user!
                    //     designer.sync();
                    // }
                }

                channel.onclose = function () {
                    console.log('channel closed.')
                }

                channel.onmessage = function (event) {
                    console.log("화이트보드!!")

                    designer.syncData(event.data);
                };
            }



            // designer.syncData({
            //     startIndex: 0,

            // });
            /** 
             * When we join a group, our signaling server will send out 'addPeer' events to each pair
             * of users in the group (creating a fully-connected graph of users, ie if there are 6 people
             * in the channel you will connect directly to the other 5, so there will be a total of 15 
             * connections in the network). 
             */
            signaling_socket.on('addPeer', function (config) {
                console.log('Signaling server said to add peer:', config);
                var peer_id = config.peer_id;
                if (peer_id in peers) {
                    /* This could happen if the user joins multiple channels where the other peer is also in. */
                    console.log("Already connected to peer ", peer_id);
                    return;
                }
                peer_connection = new RTCPeerConnection({
                        "iceServers": ICE_SERVERS
                    }, {
                        "optional": [{
                            "DtlsSrtpKeyAgreement": true
                        }]
                    }
                    /* this will no longer be needed by chrome
                     * eventually (supposedly), but is necessary 
                     * for now to get firefox to talk to chrome */
                );

                // is initiator
                if (Object.keys(peers).length === 0) {
                    console.log('creating data channel')
                    data_channel = peer_connection.createDataChannel("whiteboard", {
                        negotiated: true,
                        id: 0
                    });
                    createConnection(data_channel);
                } else {
                    console.log('===============')
                    peer_connection.ondatachannel = function (event) {
                        console.log("$$$$$")
                        // trace('Receive Channel Callback');
                        receive_channel = event.channel;
                        onDataChannelCreated(receive_channel);
                        // receiveChannel.onmessage = onReceiveMessageCallback;

                        // receiveChannel.onopen = onReceiveChannelStateChange;
                        // receiveChannel.onclose = onReceiveChannelStateChange;
                    }
                }

                peers[peer_id] = peer_connection;

                peer_connection.onicecandidate = function (event) {
                    if (event.candidate) {
                        signaling_socket.emit('relayICECandidate', {
                            'peer_id': peer_id,
                            'ice_candidate': {
                                'sdpMLineIndex': event.candidate.sdpMLineIndex,
                                'candidate': event.candidate.candidate
                            }
                        });
                    }
                }
                peer_connection.onaddstream = function (event) {
                    console.log("onAddStream", event);
                    var remote_media = USE_VIDEO ? $("<video id=" + peer_id + ">") : $("<audio>");
                    remote_media.attr("autoplay", "autoplay");
                    if (MUTE_AUDIO_BY_DEFAULT) {
                        remote_media.attr("muted", "true");
                    }
                    remote_media.attr("controls", "");
                    peer_media_elements[peer_id] = remote_media;
                    $('body').append(remote_media);
                    attachMediaStream(remote_media[0], event.stream);
                }

                /* Add our local stream */
                peer_connection.addStream(local_media_stream);

                /* Only one side of the peer connection should create the
                 * offer, the signaling server picks one to be the offerer. 
                 * The other user will get a 'sessionDescription' event and will
                 * create an offer, then send back an answer 'sessionDescription' to us
                 */
                if (config.should_create_offer) {
                    console.log("Creating RTC offer to ", peer_id);
                    peer_connection.createOffer(
                        function (local_description) {
                            console.log("Local offer description is: ", local_description);
                            peer_connection.setLocalDescription(local_description,
                                function () {
                                    signaling_socket.emit('relaySessionDescription', {
                                        'peer_id': peer_id,
                                        'session_description': local_description
                                    });
                                    console.log("Offer setLocalDescription succeeded");
                                },
                                function () {
                                    Alert("Offer setLocalDescription failed!");
                                }
                            );
                        },
                        function (error) {
                            console.log("Error sending offer: ", error);
                        });
                }



                function onReceiveMessageCallback(event) {
                    console.log('Received Message');
                    console.log("화이트보드!!")
                    // designer.syncData(event.data);
                }
            });


            /** 
             * Peers exchange session descriptions which contains information
             * about their audio / video settings and that sort of stuff. First
             * the 'offerer' sends a description to the 'answerer' (with type
             * "offer"), then the answerer sends one back (with type "answer").  
             */
            signaling_socket.on('sessionDescription', function (config) {
                console.log('Remote description received: ', config);
                var peer_id = config.peer_id;
                var peer = peers[peer_id];
                var remote_description = config.session_description;
                console.log(config.session_description);

                var desc = new RTCSessionDescription(remote_description);
                var stuff = peer.setRemoteDescription(desc,
                    function () {
                        console.log("setRemoteDescription succeeded");
                        if (remote_description.type == "offer") {
                            console.log("Creating answer");
                            peer.createAnswer(
                                function (local_description) {
                                    console.log("Answer description is: ", local_description);
                                    peer.setLocalDescription(local_description,
                                        function () {
                                            signaling_socket.emit('relaySessionDescription', {
                                                'peer_id': peer_id,
                                                'session_description': local_description
                                            });
                                            console.log("Answer setLocalDescription succeeded");
                                        },
                                        function () {
                                            Alert("Answer setLocalDescription failed!");
                                        }
                                    );
                                },
                                function (error) {
                                    console.log("Error creating answer: ", error);
                                    console.log(peer);
                                });
                        }
                    },
                    function (error) {
                        console.log("setRemoteDescription error: ", error);
                    }
                );
                console.log("Description Object: ", desc);

            });

            /**
             * The offerer will send a number of ICE Candidate blobs to the answerer so they 
             * can begin trying to find the best path to one another on the net.
             */
            signaling_socket.on('iceCandidate', function (config) {
                var peer = peers[config.peer_id];
                var ice_candidate = config.ice_candidate;
                peer.addIceCandidate(new RTCIceCandidate(ice_candidate));
            });


            /**
             * When a user leaves a channel (or is disconnected from the
             * signaling server) everyone will recieve a 'removePeer' message
             * telling them to trash the media channels they have open for those
             * that peer. If it was this client that left a channel, they'll also
             * receive the removePeers. If this client was disconnected, they
             * wont receive removePeers, but rather the
             * signaling_socket.on('disconnect') code will kick in and tear down
             * all the peer sessions.
             */
            signaling_socket.on('removePeer', function (config) {
                console.log('Signaling server said to remove peer:', config);
                var peer_id = config.peer_id;
                if (peer_id in peer_media_elements) {
                    peer_media_elements[peer_id].remove();
                }
                if (peer_id in peers) {
                    peers[peer_id].close();
                }

                delete peers[peer_id];
                delete peer_media_elements[config.peer_id];
            });
        }




        /***********************/
        /** Local media stuff **/
        /***********************/
        function setup_local_media(callback, errorback) {
            if (local_media_stream != null) {
                /* ie, if we've already been initialized */
                if (callback) callback();
                return;
            }
            /* Ask user for permission to use the computers microphone and/or camera, 
             * attach it to an <audio> or <video> tag if they give us access. */
            console.log("Requesting access to local audio / video inputs");


            navigator.getUserMedia = (navigator.getUserMedia ||
                navigator.webkitGetUserMedia ||
                navigator.mozGetUserMedia ||
                navigator.msGetUserMedia);

            attachMediaStream = function (element, stream) {
                console.log('DEPRECATED, attachMediaStream will soon be removed.');
                element.srcObject = stream;
            };

            navigator.getUserMedia({
                    "audio": USE_AUDIO,
                    "video": USE_VIDEO
                },
                function (stream) {
                    /* user accepted access to a/v */
                    console.log("Access granted to audio/video");
                    local_media_stream = stream;
                    local_media = USE_VIDEO ? $("<video id='localVideo' height='240' width='320'>") : $("<audio>");
                    local_media.attr("autoplay", "autoplay");
                    local_media.attr("muted", "true"); /* always mute ourselves by default */
                    local_media.attr("controls", "");
                    $('body').append(local_media);
                    attachMediaStream(local_media[0], stream);

                    if (callback) callback();
                },
                function () {
                    /* user denied access to a/v */
                    console.log("Access denied for audio/video");
                    alert("You chose not to provide access to the camera/microphone, demo will not work.");
                    if (errorback) errorback();
                });

            var shareButton = $('#shareScreenBtn');
            shareButton.click(startCapture);

            // 화면공유 옵션
            const captureOption = {
                audio: true,
                video: true
            }

            // 화면공유
            let captureStream = null;

            async function startCapture(captureOption) {
                try {
                    console.log("공유")
                    console.log(local_media[0])
                    captureStream = await navigator.mediaDevices.getDisplayMedia(captureOption)
                    local_media_stream = captureStream
                    attachMediaStream(local_media[0], local_media_stream)
                } catch (err) {
                    console.error("Error: " + err);
                }
                peer_connection.addStream(local_media_stream)
            }

            // 흐린배경
            var blurButton = $('#blurScreenBtn');
            var canvas;
            blurButton.click(blurScreen);

            async function blurScreen() {
                if (!canvas) {
                    $('body').append("<canvas id='canvas' height='240' width='320'></canvas>");
                    canvas = $('#canvas')[0];
                }

                canvas.height = local_media[0].videoHeight;
                canvas.width = local_media[0].videoWidth;

                let options = {
                    multiplier: 0.75,
                    stride: 32,
                    quantBytes: 4
                }

                bodyPix.load(options)
                    .then(net => perform(net))
                    .catch(err => console.log(err))

                let blurStream = await canvas.captureStream();
                if (blurStream) {
                    local_media_stream = blurStream
                    setTimeout(function () {
                            attachMediaStream(local_media[0], local_media_stream)
                            peer_connection.addStream(local_media_stream)
                        },
                        5000);
                }
            }

            async function perform(net) {
                while (1) {
                    const segmentation = await net.segmentPerson(local_media[0]);

                    const backgroundBlurAmount = 6;
                    const edgeBlurAmount = 2;
                    const flipHorizontal = true;

                    await bodyPix.drawBokehEffect(canvas, local_media[0], segmentation,
                        backgroundBlurAmount,
                        edgeBlurAmount, flipHorizontal);
                }

            }

            // 화이트보드
            var whiteboardButton = $('#whiteboardBtn');
            whiteboardButton.click(startWhiteboard);

            var whiteboardShareButton = $('#whiteboardShareBtn');
            whiteboardShareButton.click(whiteboardShare);

            async function startWhiteboard() {
                // $('#canvas').append(canvas.getHtml());
                // canvas.onInsert();
                // canvas.api.startEditing();
                // createConnection();
                data_channel.send("안녕");
                designer.appendTo(document.body || document.documentElement);
                designer.addSyncListener(function (data) {
                    console.log("화이트보드 받아!!")
                    data_channel.send(data);
                });
                designer.captureStream(function (stream) {
                    console.log(stream)
                    local_media_stream = stream
                    attachMediaStream(local_media[0], local_media_stream)
                });
            }

            function whiteboardShare() {

            }
        }
    </script>
</head>

<body onload='init()'>
    <!-- 
        the <video> and <audio> tags are all added and removed dynamically
        in 'onAddStream', 'setup_local_media', and 'removePeer'/'disconnect'
        -->
    <div class="btn-group">
        <button class="button" id="shareScreenBtn">공유</button>
        <button class="button" id="recordScreenBtn">녹화시작</button>
        <button class="button" id="blurScreenBtn">흐린배경</button>
        <button class="button" id="whiteboardBtn">화이트보드</button>
        <button class="button" id="whiteboardShareBtn">화이트보드 공유</button>
    </div>
    <video id="canvasVideo"></video>

    <script>
        /** for whiteboard */
        var designer = new CanvasDesigner(peer_connection);
        // both links are mandatory
        // widget.html will internally use widget.js
        designer.widgetHtmlURL =
            'https://www.webrtc-experiment.com/Canvas-Designer/widget.html'; // you can place this file anywhere
        designer.widgetJsURL =
            'https://www.webrtc-experiment.com/Canvas-Designer/widget.js'; // you can place this file anywhere
        designer.addSyncListener(function (data) {
            console.log("화이트보드 받아!!")
            data_channel.send(data);
            designer.send(JSON.stringify(data));
        });
        designer.captureStream(function (stream) {
            var url = URL.createObjectURL(stream);
            console.log(url)
            videoPreview.src = url;

            peer_connection.addStream(stream);
            peer_connection.createOffer(success, failure, params);
        });
    </script>
</body>

</html>